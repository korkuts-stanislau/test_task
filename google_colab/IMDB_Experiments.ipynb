{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_Experiments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-9IPxvP-gDt"
      },
      "source": [
        "<h2>Hello, it is my notebook with experiments with IMDB Movies Dataset task solving models</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciESln9i-vJR"
      },
      "source": [
        "<h4>Import modules and load data</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhBi4z-y2O1r"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkhiiuFR7mAu"
      },
      "source": [
        "data = pd.read_csv(\"IMDB Dataset.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGGGdI-X7rBL",
        "outputId": "36298d84-04d5-441c-ca8f-be076c978d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YEO4UV2-1G5"
      },
      "source": [
        "<h4>Make labels numerical</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUnkjWFq715T"
      },
      "source": [
        "data = pd.DataFrame({\"review\": data[\"review\"], \"sentiment\": data[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})})"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YayWK9bj8KyZ",
        "outputId": "59bedc9a-bb28-4bf4-8729-b53284bb3537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj7YR8-r-9hQ"
      },
      "source": [
        "<h4>Split the model into two parts - train set and test set</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8coQg0CV8XJF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2co21mKa8Qzd"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.drop([\"sentiment\"], axis=1), data[\"sentiment\"], test_size=0.3, random_state=7)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo1_wnFW8rlm",
        "outputId": "4de61ec2-3360-4b37-8bdb-9b8bc836d6b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46521</th>\n",
              "      <td>Sam Fuller's excellent PICK UP ON SOUTH STREET...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13908</th>\n",
              "      <td>If at all possible, try to view all five of th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39915</th>\n",
              "      <td>THE 40 YEAR-OLD VIRGIN (2005) **** Steve Carel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28440</th>\n",
              "      <td>I had seen Rik Mayall in Blackadder and the Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6011</th>\n",
              "      <td>I have seen Maslin Beach a couple of times - b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review\n",
              "46521  Sam Fuller's excellent PICK UP ON SOUTH STREET...\n",
              "13908  If at all possible, try to view all five of th...\n",
              "39915  THE 40 YEAR-OLD VIRGIN (2005) **** Steve Carel...\n",
              "28440  I had seen Rik Mayall in Blackadder and the Ne...\n",
              "6011   I have seen Maslin Beach a couple of times - b..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6rauT4T8u9g",
        "outputId": "71ca3617-8417-4c5e-8864-551030943f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46521    1\n",
              "13908    0\n",
              "39915    1\n",
              "28440    0\n",
              "6011     1\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsIwqKBW_FaJ"
      },
      "source": [
        "<h4>Make pipeline component for text normalize</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLc77UIF8wzl"
      },
      "source": [
        "import re\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS as stop_words\n",
        "from spacy.lang.en import English"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-8FMUbF9OB-"
      },
      "source": [
        "parser = English()\n",
        "punctuations = string.punctuation"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc8mxRYS9Qnk"
      },
      "source": [
        "def spacy_text_normalizer(text):\n",
        "    text = re.sub(r\"<.*>\", \"\", text) #Remove all tags\n",
        "    tokens = parser(text) #Get doc from text\n",
        "    tokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens ] #Normalize words\n",
        "    tokens = [ word for word in tokens if word not in stop_words and word not in punctuations ] #Remove stop words and punctuation\n",
        "    return \" \".join(tokens)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0YIQFhp9cRr"
      },
      "source": [
        "from sklearn.base import TransformerMixin"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFWHV74x9hLx"
      },
      "source": [
        "class TextNormalizer(TransformerMixin):\n",
        "    def __init__(self, text_column_name = \"review\"):\n",
        "        self.text_column_name = text_column_name\n",
        "        \n",
        "    def transform(self, X, **transform_params):\n",
        "        return [spacy_text_normalizer(text) for text in X[self.text_column_name]]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNwA2Pqu-esU"
      },
      "source": [
        "<h4>The next step is to tune text vectorizer. First of all you need to choose binary classification model. I chose logistic regression</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhGMjpFs91HY"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY2HhR6v_uYg"
      },
      "source": [
        "<h4>Importing required modules</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVXixzlm_tvX"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYxxcZesAFp7"
      },
      "source": [
        "<h4>Let's make 2 pipelines, tune hyperparameters and choose vectorizer</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjZ7A1J_AFDb"
      },
      "source": [
        "count_pipe = Pipeline([\n",
        "  (\"normalizer\", TextNormalizer()),\n",
        "  (\"vectorizer\", CountVectorizer()),\n",
        "  (\"classifier\", LogisticRegression())\n",
        "])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_deHscvApzx"
      },
      "source": [
        "tfidf_pipe = Pipeline([\n",
        "  (\"normalizer\", TextNormalizer()),\n",
        "  (\"vectorizer\", TfidfVectorizer()),\n",
        "  (\"classifier\", LogisticRegression())\n",
        "])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIeE6BcTA4an"
      },
      "source": [
        "<h4>Let's write metrics function</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxX7TDfXAyl4"
      },
      "source": [
        "def get_metrics_values(model, X, y, metric):\n",
        "  y_pred = model.predict(X)\n",
        "  return metric(y_pred, y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ-2o0QUDGlF"
      },
      "source": [
        "<h4>Fit pipelines</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgm36TpzBeRy",
        "outputId": "d04f2d77-047a-444a-8283-f4fb6f57e0ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "count_pipe.fit(X_train, y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 48.5 s, sys: 2.74 s, total: 51.2 s\n",
            "Wall time: 48.1 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('normalizer',\n",
              "                 <__main__.TextNormalizer object at 0x7f6885a00400>),\n",
              "                ('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY_DkeyaBmuY",
        "outputId": "415a29a7-dd3f-4bce-e809-251345ada075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "tfidf_pipe.fit(X_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 45.5 s, sys: 1.63 s, total: 47.1 s\n",
            "Wall time: 45.2 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('normalizer',\n",
              "                 <__main__.TextNormalizer object at 0x7f6885a006a0>),\n",
              "                ('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 s...\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH0zWLsnDKgp"
      },
      "source": [
        "<h4>Let's import some metrics and check models</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFLAdgtiB0Bc"
      },
      "source": [
        "from sklearn import metrics\n",
        "metrics = {\n",
        "    \"accuracy\": metrics.accuracy_score,\n",
        "    \"precision\": metrics.precision_score,\n",
        "    \"recall\": metrics.recall_score,\n",
        "    \"f1\": metrics.f1_score\n",
        "}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tesDaBhLB4eX",
        "outputId": "27746df2-c6dc-42df-f0d1-514db0609c4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"CountVectorizer metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(count_pipe, X_test, y_test, metric)}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer metrics\n",
            "accuracy value is 0.8433333333333334\n",
            "precision value is 0.8471760797342193\n",
            "recall value is 0.8415841584158416\n",
            "f1 value is 0.8443708609271523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96I-im2gCPZW",
        "outputId": "38b0bf16-d923-4d73-c8ec-d3dbdeee6949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"TfIdfVectorizer metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(tfidf_pipe, X_test, y_test, metric)}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TfIdfVectorizer metrics\n",
            "accuracy value is 0.8552\n",
            "precision value is 0.8699003322259137\n",
            "recall value is 0.84584571650084\n",
            "f1 value is 0.8577044025157233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn3MRS2YFqWO"
      },
      "source": [
        "<h4>Let's look at the features count</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVtGo5cWGl03",
        "outputId": "acb976a6-7a30-4685-9683-38be362205ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(tfidf_pipe[\"vectorizer\"].get_feature_names())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XIZR_tnDTb_"
      },
      "source": [
        "<h4>TfIdf is a little bit better. Lets tune hyperparameters</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4dWgg6RCSO3"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkHCvNdRDtnW"
      },
      "source": [
        "skf = StratifiedKFold(n_splits=3)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5aJ8dTkD4EW"
      },
      "source": [
        "param_grid = {\n",
        "    'vectorizer__ngram_range': ((1, 1), (1, 2), (2, 2)),\n",
        "    'vectorizer__max_features': (10000, 40000, None)\n",
        "}"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdDJkYkbHihA"
      },
      "source": [
        "<h4>For time economy make new dataset with cleaned data and new pipes</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfaNsjiWHxm1"
      },
      "source": [
        "X_train_clean = TextNormalizer().fit_transform(X_train)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDZJPjp-IYpg"
      },
      "source": [
        "count_logreg_pipe = Pipeline([\n",
        "  (\"vectorizer\", CountVectorizer()),\n",
        "  (\"classifier\", LogisticRegression())            \n",
        "])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgoLG1ilIpAR"
      },
      "source": [
        "tfidf_logreg_pipe = Pipeline([\n",
        "  (\"vectorizer\", TfidfVectorizer()),\n",
        "  (\"classifier\", LogisticRegression())\n",
        "])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "798k9Yt0I2OX"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3U2Wq0lA6AT"
      },
      "source": [
        "<h4>Lets tune hyperparameters</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGLjM-EEHBSa",
        "outputId": "7bc00917-9631-429a-812f-d48ca2778643",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "count_search = GridSearchCV(count_logreg_pipe, param_grid, n_jobs=-1)\n",
        "count_search.fit(X_train_clean, y_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vectorizer',\n",
              "                                        CountVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        preprocessor=None,\n",
              "                                                        stop_words=None,\n",
              "                                                        strip_accents=None,\n",
              "                                                        token_patt...\n",
              "                                                           max_iter=100,\n",
              "                                                           multi_class='auto',\n",
              "                                                           n_jobs=None,\n",
              "                                                           penalty='l2',\n",
              "                                                           random_state=None,\n",
              "                                                           solver='lbfgs',\n",
              "                                                           tol=0.0001,\n",
              "                                                           verbose=0,\n",
              "                                                           warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'vectorizer__max_features': (10000, 40000, None),\n",
              "                         'vectorizer__ngram_range': ((1, 1), (1, 2), (2, 2))},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX5j_uD6I0_0",
        "outputId": "61ca0898-145b-45c1-9a9c-26487e94a6bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_search = GridSearchCV(tfidf_logreg_pipe, param_grid, n_jobs=-1)\n",
        "tfidf_search.fit(X_train_clean, y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vectorizer',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words=None,\n",
              "                                                        s...\n",
              "                                                           max_iter=100,\n",
              "                                                           multi_class='auto',\n",
              "                                                           n_jobs=None,\n",
              "                                                           penalty='l2',\n",
              "                                                           random_state=None,\n",
              "                                                           solver='lbfgs',\n",
              "                                                           tol=0.0001,\n",
              "                                                           verbose=0,\n",
              "                                                           warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'vectorizer__max_features': (10000, 40000, None),\n",
              "                         'vectorizer__ngram_range': ((1, 1), (1, 2), (2, 2))},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS5yuKDfBi25"
      },
      "source": [
        "<h4>Look at the best models</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wej4YnfuJIQn",
        "outputId": "aea772e1-6d6b-4b01-d3a7-99eb1e9acde6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "count_search.best_score_"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXyh08wkBsvL",
        "outputId": "3a43b43c-988b-4244-a70a-1cfb84b50445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "count_search.best_params_"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vectorizer__max_features': None, 'vectorizer__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ-ujsxfB-9o",
        "outputId": "5f44b979-15d3-40c9-fd9a-535e323c4e76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_search.best_score_"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8604857142857142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUF6kFyICDb5",
        "outputId": "460067e9-a593-465f-8334-1473599358cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_search.best_params_"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vectorizer__max_features': 40000, 'vectorizer__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stka5vHjDL-l"
      },
      "source": [
        "<h4>Lets check on the test dataset</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5obqmQpYC8Tx"
      },
      "source": [
        "X_test_cleaned = TextNormalizer().fit_transform(X_test)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhOIKHLyCOel",
        "outputId": "bfc75d1e-cfbc-47da-ce05-b7eecc11e3ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"CountVectorizer metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(count_search, X_test_cleaned, y_test, metric)}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer metrics\n",
            "accuracy value is 0.8556666666666667\n",
            "precision value is 0.8623255813953489\n",
            "recall value is 0.8517983722761879\n",
            "f1 value is 0.857029650663673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH8eevowDSTe",
        "outputId": "411d4986-11eb-44ca-e48d-c36f7812fd29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"TFidfVectorizer metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(tfidf_search, X_test_cleaned, y_test, metric)}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFidfVectorizer metrics\n",
            "accuracy value is 0.8587333333333333\n",
            "precision value is 0.8742857142857143\n",
            "recall value is 0.8486842105263158\n",
            "f1 value is 0.8612947568239838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t16PdadDkzW"
      },
      "source": [
        "<h4>Tfidf a little bit better. Lets tune this hyperparameters more</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcB75pShDfnI"
      },
      "source": [
        "param_grid = {\n",
        "    'vectorizer__max_df': (0.25, 0.5, 0.75),\n",
        "    'vectorizer__ngram_range': ((1, 2), (1, 3)),\n",
        "    'vectorizer__max_features': (40000, 100000, None)\n",
        "}"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd5qtpPhE_HI",
        "outputId": "9953e1b0-cbcc-4a44-bce3-5189b8e06f01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_search = GridSearchCV(tfidf_logreg_pipe, param_grid, n_jobs=-1)\n",
        "tfidf_search.fit(X_train_clean, y_train)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vectorizer',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words=None,\n",
              "                                                        s...\n",
              "                                                           n_jobs=None,\n",
              "                                                           penalty='l2',\n",
              "                                                           random_state=None,\n",
              "                                                           solver='lbfgs',\n",
              "                                                           tol=0.0001,\n",
              "                                                           verbose=0,\n",
              "                                                           warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'vectorizer__max_df': (0.25, 0.5, 0.75),\n",
              "                         'vectorizer__max_features': (40000, 100000, None),\n",
              "                         'vectorizer__ngram_range': ((1, 2), (1, 3))},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XXRHE7MMBSK"
      },
      "source": [
        "<h4>Lets look at the best parameters and score</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6QpYrB1FEoA",
        "outputId": "ef2e74bc-cdd8-4e08-8114-0c626c826cd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_search.best_params_"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vectorizer__max_df': 0.25,\n",
              " 'vectorizer__max_features': 100000,\n",
              " 'vectorizer__ngram_range': (1, 3)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI3rSQ_HMLpe",
        "outputId": "2e79484a-c666-487a-ad2b-2295e898fea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_search.best_score_"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8610857142857142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4YloRpsMOj9",
        "outputId": "27c8bff3-2871-4e26-d288-b6348d701b18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"TFidfVectorizer metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(tfidf_search, X_test_cleaned, y_test, metric)}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFidfVectorizer metrics\n",
            "accuracy value is 0.8582\n",
            "precision value is 0.8742857142857143\n",
            "recall value is 0.8478092783505154\n",
            "f1 value is 0.8608439646712462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GspA0nCNZEG"
      },
      "source": [
        "<h4>Setting did not give meaningful results. Probably need to change the classifier. Lets save the model and tune classifier</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyOWJCPcOq0K"
      },
      "source": [
        "tfidf = tfidf_search.best_estimator_[\"vectorizer\"]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA6yEol2MY3P"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b_fV-IwOiyo"
      },
      "source": [
        "pickle.dump(tfidf, open(\"tfidf.pickle\", \"wb\"))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xchJiSdaP5g2"
      },
      "source": [
        "<h4>Lets tune classifier</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT1iyVUURTAR"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go92XRGVPoy6"
      },
      "source": [
        "param_grid = {\n",
        "    'classifier__penalty' : ['l1', 'l2'],\n",
        "    'classifier__C' : np.logspace(-4, 4, 5)\n",
        "}"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipwMHaa5RQRM",
        "outputId": "1c67c661-a844-44e2-f306-18a375255a1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_logreg_pipe = Pipeline([\n",
        "  (\"vectorizer\", tfidf),\n",
        "  (\"classifier\", LogisticRegression())\n",
        "])\n",
        "tfidf_search = GridSearchCV(tfidf_logreg_pipe, param_grid, n_jobs=-1)\n",
        "tfidf_search.fit(X_train_clean, y_train)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vectorizer',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=0.25,\n",
              "                                                        max_features=100000,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 3),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words=Non...\n",
              "                                                           multi_class='auto',\n",
              "                                                           n_jobs=None,\n",
              "                                                           penalty='l2',\n",
              "                                                           random_state=None,\n",
              "                                                           solver='lbfgs',\n",
              "                                                           tol=0.0001,\n",
              "                                                           verbose=0,\n",
              "                                                           warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'classifier__C': array([1.e-04, 1.e-02, 1.e+00, 1.e+02, 1.e+04]),\n",
              "                         'classifier__penalty': ['l1', 'l2']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgaErqc1Re4y",
        "outputId": "0f15dfad-e6bf-46a9-c98d-83a9eee765e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_search.best_score_"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8610857142857142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhQpoNiZWkqM",
        "outputId": "a0958aac-6db8-4f41-c45d-70414fce4897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_search.best_params_"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier__C': 1.0, 'classifier__penalty': 'l2'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUKsaCGhWoxl",
        "outputId": "0a206b8f-199f-4f1e-d824-8bff8a6aaa64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"TFidfVectorizer metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(tfidf_search, X_test_cleaned, y_test, metric)}\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFidfVectorizer metrics\n",
            "accuracy value is 0.8582\n",
            "precision value is 0.8742857142857143\n",
            "recall value is 0.8478092783505154\n",
            "f1 value is 0.8608439646712462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU7Hg5XNXrGY"
      },
      "source": [
        "logreg = tfidf_search.best_estimator_[\"classifier\"]"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILlUxZUyW_-k"
      },
      "source": [
        "<h4>Maybe need to make an ensemble</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YpociDAX2Fi"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-IHLR31YG-Q"
      },
      "source": [
        "param_grid = {\n",
        "    'classifier__n_estimators' : (5, 10, 15)\n",
        "}"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn493V8pW7WG"
      },
      "source": [
        "bagging_logreg = BaggingClassifier(logreg, bootstrap = True, random_state = 7)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ryTJ8MiX0e3",
        "outputId": "e4c08b23-d787-4b87-c182-412ad2e29daf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_bagging_pipe = Pipeline([\n",
        "  (\"vectorizer\", tfidf),\n",
        "  (\"classifier\", bagging_logreg)\n",
        "])\n",
        "tfidf_bagging_search = GridSearchCV(tfidf_bagging_pipe, param_grid, n_jobs=-1)\n",
        "tfidf_bagging_search.fit(X_train_clean, y_train)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vectorizer',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=0.25,\n",
              "                                                        max_features=100000,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 3),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words=Non...\n",
              "                                                                                            warm_start=False),\n",
              "                                                          bootstrap=True,\n",
              "                                                          bootstrap_features=False,\n",
              "                                                          max_features=1.0,\n",
              "                                                          max_samples=1.0,\n",
              "                                                          n_estimators=10,\n",
              "                                                          n_jobs=None,\n",
              "                                                          oob_score=False,\n",
              "                                                          random_state=7,\n",
              "                                                          verbose=0,\n",
              "                                                          warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'classifier__n_estimators': (5, 10, 15)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGuV2Gy-Yj1o",
        "outputId": "49f3e54c-8718-4f05-c513-aad0a47ccf72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_bagging_search.best_params_"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier__n_estimators': 15}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-TuuVugcwLP",
        "outputId": "9507e005-f0ee-4804-8916-7cb02f75818f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_bagging_search.best_score_"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8583714285714287"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p7V3ZrWczzj",
        "outputId": "ccbba367-6352-4688-8093-10b24017a1ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Bagging metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(tfidf_bagging_search, X_test_cleaned, y_test, metric)}\")"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bagging metrics\n",
            "accuracy value is 0.8564666666666667\n",
            "precision value is 0.8754817275747508\n",
            "recall value is 0.8441824705279344\n",
            "f1 value is 0.8595472633570356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoSU7OsEdZJz"
      },
      "source": [
        "<h4>Bagging is worse than a single classifier</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHACR7Pddvsh"
      },
      "source": [
        "<h3>Summary</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFyRu7UpdzAw"
      },
      "source": [
        "<h4>Maybe we need to work not with BOW models but with sequences models.In other notebook i try to use neural nets for solving this problem.</h4>"
      ]
    }
  ]
}