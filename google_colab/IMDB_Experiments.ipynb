{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_Experiments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-9IPxvP-gDt"
      },
      "source": [
        "<h2>Hello, it is my notebook with experiments with IMDB Movies Dataset task solving models</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciESln9i-vJR"
      },
      "source": [
        "<h4>Import modules and load data</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhBi4z-y2O1r"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkhiiuFR7mAu"
      },
      "source": [
        "data = pd.read_csv(\"IMDB Dataset.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGGGdI-X7rBL",
        "outputId": "ff4d5848-aff2-423b-a74e-3e015f71d506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YEO4UV2-1G5"
      },
      "source": [
        "<h4>Make labels numerical</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUnkjWFq715T"
      },
      "source": [
        "data = pd.DataFrame({\"review\": data[\"review\"], \"sentiment\": data[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})})"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YayWK9bj8KyZ",
        "outputId": "52edc1ab-edb5-4b63-b82e-2d1bdf6a9d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj7YR8-r-9hQ"
      },
      "source": [
        "<h4>Split the model into two parts - train set and test set</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8coQg0CV8XJF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2co21mKa8Qzd"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.drop([\"sentiment\"], axis=1), data[\"sentiment\"], test_size=0.3, random_state=7)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo1_wnFW8rlm",
        "outputId": "4baea1ea-31a7-418d-9302-4af65b949d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46521</th>\n",
              "      <td>Sam Fuller's excellent PICK UP ON SOUTH STREET...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13908</th>\n",
              "      <td>If at all possible, try to view all five of th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39915</th>\n",
              "      <td>THE 40 YEAR-OLD VIRGIN (2005) **** Steve Carel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28440</th>\n",
              "      <td>I had seen Rik Mayall in Blackadder and the Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6011</th>\n",
              "      <td>I have seen Maslin Beach a couple of times - b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review\n",
              "46521  Sam Fuller's excellent PICK UP ON SOUTH STREET...\n",
              "13908  If at all possible, try to view all five of th...\n",
              "39915  THE 40 YEAR-OLD VIRGIN (2005) **** Steve Carel...\n",
              "28440  I had seen Rik Mayall in Blackadder and the Ne...\n",
              "6011   I have seen Maslin Beach a couple of times - b..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6rauT4T8u9g",
        "outputId": "1b110438-7034-4881-fd8a-8fcee8d9056b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46521    1\n",
              "13908    0\n",
              "39915    1\n",
              "28440    0\n",
              "6011     1\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsIwqKBW_FaJ"
      },
      "source": [
        "<h4>Make pipeline component for text normalize</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLc77UIF8wzl"
      },
      "source": [
        "import re\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS as stop_words\n",
        "from spacy.lang.en import English"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-8FMUbF9OB-"
      },
      "source": [
        "parser = English()\n",
        "punctuations = string.punctuation"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc8mxRYS9Qnk"
      },
      "source": [
        "def spacy_text_normalizer(text):\n",
        "    text = re.sub(r\"<.*>\", \"\", text) #Remove all tags\n",
        "    tokens = parser(text) #Get doc from text\n",
        "    tokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens ] #Normalize words\n",
        "    tokens = [ word for word in tokens if word not in stop_words and word not in punctuations ] #Remove stop words and punctuation\n",
        "    return \" \".join(tokens)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0YIQFhp9cRr"
      },
      "source": [
        "from sklearn.base import TransformerMixin"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFWHV74x9hLx"
      },
      "source": [
        "class TextNormalizer(TransformerMixin):\n",
        "    def __init__(self, text_column_name = \"review\"):\n",
        "        self.text_column_name = text_column_name\n",
        "        \n",
        "    def transform(self, X, **transform_params):\n",
        "        return [spacy_text_normalizer(text) for text in X[self.text_column_name]]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {}"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNwA2Pqu-esU"
      },
      "source": [
        "<h4>The next step is to tune text vectorizer. First of all you need to choose binary classification model. I chose logistic regression</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhGMjpFs91HY"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY2HhR6v_uYg"
      },
      "source": [
        "<h4>Importing required modules</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVXixzlm_tvX"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYxxcZesAFp7"
      },
      "source": [
        "<h4>Let's make 2 pipelines, tune hyperparameters and choose vectorizer</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjZ7A1J_AFDb"
      },
      "source": [
        "count_pipe = Pipeline([\n",
        "  (\"normalizer\", TextNormalizer()),\n",
        "  (\"vectorizer\", CountVectorizer()),\n",
        "  (\"classifier\", LogisticRegression())\n",
        "])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_deHscvApzx"
      },
      "source": [
        "tfidf_pipe = Pipeline([\n",
        "  (\"normalizer\", TextNormalizer()),\n",
        "  (\"vectorizer\", TfidfVectorizer()),\n",
        "  (\"classifier\", LogisticRegression())\n",
        "])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIeE6BcTA4an"
      },
      "source": [
        "<h4>Let's write metrics function</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxX7TDfXAyl4"
      },
      "source": [
        "def get_metrics_values(model, X, y, metric):\n",
        "  y_pred = model.predict(X)\n",
        "  return metric(y_pred, y)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ-2o0QUDGlF"
      },
      "source": [
        "<h4>Fit pipelines</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgm36TpzBeRy",
        "outputId": "f4282571-848f-44ee-b8cd-c01d12a87475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "count_pipe.fit(X_train, y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 46.6 s, sys: 2.43 s, total: 49.1 s\n",
            "Wall time: 46.3 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('normalizer',\n",
              "                 <__main__.TextNormalizer object at 0x7fbfb145da58>),\n",
              "                ('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY_DkeyaBmuY",
        "outputId": "5e9e78ad-6508-4555-e6e3-47bdf9e9228f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "tfidf_pipe.fit(X_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 43.7 s, sys: 1.4 s, total: 45.1 s\n",
            "Wall time: 43.5 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('normalizer',\n",
              "                 <__main__.TextNormalizer object at 0x7fbfb1437d30>),\n",
              "                ('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 s...\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH0zWLsnDKgp"
      },
      "source": [
        "<h4>Let's import some metrics and check models</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFLAdgtiB0Bc"
      },
      "source": [
        "from sklearn import metrics\n",
        "metrics = {\n",
        "    \"accuracy\": metrics.accuracy_score,\n",
        "    \"precision\": metrics.precision_score,\n",
        "    \"recall\": metrics.recall_score,\n",
        "    \"f1\": metrics.f1_score\n",
        "}"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tesDaBhLB4eX",
        "outputId": "54ceb3cc-4b03-4fd4-e6b9-c4ba76959472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"CountVectorizer metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(count_pipe, X_test, y_test, metric)}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer metrics\n",
            "accuracy value is 0.8433333333333334\n",
            "precision value is 0.8471760797342193\n",
            "recall value is 0.8415841584158416\n",
            "f1 value is 0.8443708609271523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96I-im2gCPZW",
        "outputId": "35bbdc86-b746-49c2-a0be-e9e460b79419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"TfIdfVectorizer metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(tfidf_pipe, X_test, y_test, metric)}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TfIdfVectorizer metrics\n",
            "accuracy value is 0.8552\n",
            "precision value is 0.8699003322259137\n",
            "recall value is 0.84584571650084\n",
            "f1 value is 0.8577044025157233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn3MRS2YFqWO"
      },
      "source": [
        "<h4>Let's look at the features count</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVtGo5cWGl03",
        "outputId": "e8ac7f7d-ec57-47db-fdc5-2aeca0ce8a3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(tfidf_pipe[\"vectorizer\"].get_feature_names())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XIZR_tnDTb_"
      },
      "source": [
        "<h4>TfIdf is a little bit better. Lets tune hyperparameters</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4dWgg6RCSO3"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkHCvNdRDtnW"
      },
      "source": [
        "skf = StratifiedKFold(n_splits=3)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5aJ8dTkD4EW"
      },
      "source": [
        "param_grid = {\n",
        "    'vectorizer__ngram_range': ((1, 1), (1, 2), (2, 2)),\n",
        "    'vectorizer__max_features': (10000, 40000, None)\n",
        "}"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdDJkYkbHihA"
      },
      "source": [
        "<h4>For time economy make new dataset with cleaned data and new pipes</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfaNsjiWHxm1"
      },
      "source": [
        "X_train_clean = TextNormalizer().fit_transform(X_train)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDZJPjp-IYpg"
      },
      "source": [
        "count_logreg_pipe = Pipeline([\n",
        "  (\"vectorizer\", CountVectorizer()),\n",
        "  (\"classifier\", LogisticRegression())            \n",
        "])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgoLG1ilIpAR"
      },
      "source": [
        "tfidf_logreg_pipe = Pipeline([\n",
        "  (\"vectorizer\", TfidfVectorizer()),\n",
        "  (\"classifier\", LogisticRegression())\n",
        "])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "798k9Yt0I2OX"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGLjM-EEHBSa",
        "outputId": "ece0397c-0f7c-49ef-deb5-b59c0fc5ff7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "count_search = GridSearchCV(count_logreg_pipe, param_grid, n_jobs=-1)\n",
        "count_search.fit(X_train_clean, y_train)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vectorizer',\n",
              "                                        CountVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        preprocessor=None,\n",
              "                                                        stop_words=None,\n",
              "                                                        strip_accents=None,\n",
              "                                                        token_patt...\n",
              "                                                           max_iter=100,\n",
              "                                                           multi_class='auto',\n",
              "                                                           n_jobs=None,\n",
              "                                                           penalty='l2',\n",
              "                                                           random_state=None,\n",
              "                                                           solver='lbfgs',\n",
              "                                                           tol=0.0001,\n",
              "                                                           verbose=0,\n",
              "                                                           warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'vectorizer__max_features': (10000, 40000, None),\n",
              "                         'vectorizer__ngram_range': ((1, 1), (1, 2), (2, 2))},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX5j_uD6I0_0"
      },
      "source": [
        "tfidf_search = GridSearchCV(tfidf_logreg_pipe, param_grid, n_jobs=-1)\n",
        "tfidf_search.fit(X_train_clean, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wej4YnfuJIQn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}