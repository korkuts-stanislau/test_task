{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lime.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uxKBowMZOgP"
      },
      "source": [
        "<h2>Very strange, but I have not tested how the model will work with unnormalized data.</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXHs1wxZaY5a"
      },
      "source": [
        "<h4>Import modules and load data</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYeprEcWJhDB"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C75qJ_loJrDs"
      },
      "source": [
        "data = pd.read_csv(\"IMDB_dataset.csv\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MrmFa2wad8K"
      },
      "source": [
        "<h4>Split data and make model pipeline</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lk_hx6sJ9A8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QzO_-m-J7Rd"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[\"review\"], data[\"sentiment\"], random_state=7)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzQTKv-CKusF"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsBygGwWK1rW"
      },
      "source": [
        "model = Pipeline([\n",
        "  (\"vec\", TfidfVectorizer()),\n",
        "  (\"classifier\", LogisticRegression()) \n",
        "])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PGzTfq7TLu4",
        "outputId": "8f03f101-889a-47e5-f18e-931c4a9d604f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vec',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr0OpbMjalOG"
      },
      "source": [
        "<h4>Lets watch at the most important features</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBBAAWENLfLn"
      },
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "explainer = LimeTextExplainer(class_names=[\"negative\", \"positive\"])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLjBW8Z_L6hN",
        "outputId": "5aa82d60-992e-4e1c-a39a-7de91ef0f27d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "exp = explainer.explain_instance(X_test.iloc[0], model.predict_proba, num_features=10)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lime/lime_text.py:114: FutureWarning: split() requires a non-empty pattern match.\n",
            "  self.as_list = [s for s in splitter.split(self.raw) if s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBqxnlVKUUMt",
        "outputId": "683ff017-896f-4f60-8a20-6b59c4d3de5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29430    negative\n",
              "27750    positive\n",
              "47782    positive\n",
              "10498    negative\n",
              "24747    positive\n",
              "           ...   \n",
              "27724    positive\n",
              "7648     negative\n",
              "17607    positive\n",
              "9337     negative\n",
              "47433    positive\n",
              "Name: sentiment, Length: 12500, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpIhk43tP7-r",
        "outputId": "f08a711f-1817-4738-826d-cd41984a3385",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "exp.as_list()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bad', -0.06753685618152307),\n",
              " ('Nothing', -0.05134465987067746),\n",
              " ('only', -0.04318437118727395),\n",
              " ('Oh', -0.04059057234648972),\n",
              " ('love', 0.03870124351921595),\n",
              " ('garbage', -0.031599705686315954),\n",
              " ('have', -0.03002197998428627),\n",
              " ('it', 0.028327229771188903),\n",
              " ('hours', -0.024872527827906537),\n",
              " ('least', -0.023811985590418076)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcEGGapPXfaS"
      },
      "source": [
        "y_train = y_train.map({\"positive\": 1, \"negative\": 0})\n",
        "y_test = y_test.map({\"positive\": 1, \"negative\": 0})"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I-bVy2NVX6N"
      },
      "source": [
        "from sklearn import metrics\n",
        "metrics = {\n",
        "    \"accuracy\": metrics.accuracy_score,\n",
        "    \"precision\": metrics.precision_score,\n",
        "    \"recall\": metrics.recall_score,\n",
        "    \"f1\": metrics.f1_score\n",
        "}"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pd-mT8YX1HF",
        "outputId": "3f6f804e-2274-4359-96a6-b8dd8cc8c6d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vec',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOKz3yHaW168"
      },
      "source": [
        "def get_metrics_values(model, X, y, metric):\n",
        "  y_pred = model.predict(X)\n",
        "  return metric(y_pred, y)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NQ24BErWsvV",
        "outputId": "c73713e4-befa-4426-9fba-5fbe04cfbb83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Model metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(model, X_test, y_test, metric)}\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model metrics\n",
            "accuracy value is 0.89416\n",
            "precision value is 0.9037690457097033\n",
            "recall value is 0.886284995281535\n",
            "f1 value is 0.894941634241245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Ig4NBNa1-6"
      },
      "source": [
        "<h4>Now lets normalize data and fit model</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkAoT0WEW8t7"
      },
      "source": [
        "import re\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS as stop_words\n",
        "from spacy.lang.en import English"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfEevI7jYIfu"
      },
      "source": [
        "parser = English()\n",
        "punctuations = string.punctuation"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV9uS-40YJ15"
      },
      "source": [
        "def spacy_text_normalizer(text):\n",
        "    text = re.sub(r\"<.*>\", \"\", text) #Remove all tags\n",
        "    tokens = parser(text) #Get doc from text\n",
        "    tokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens ] #Normalize words\n",
        "    tokens = [ word for word in tokens if word not in stop_words and word not in punctuations ] #Remove stop words and punctuation\n",
        "    return \" \".join(tokens)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpzth-XUYMSm"
      },
      "source": [
        "from sklearn.base import TransformerMixin"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoT6sShqYTsy"
      },
      "source": [
        "X_train = X_train.apply(spacy_text_normalizer)\n",
        "X_test = X_test.apply(spacy_text_normalizer)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7MMMIf_YZG0",
        "outputId": "3ea1ba34-e257-413e-b583-64c1eb800081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vec',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wo2bg0_Y7lm",
        "outputId": "f8afff0a-fa49-4f48-b44f-d758208ef1a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Model metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(model, X_test, y_test, metric)}\")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model metrics\n",
            "accuracy value is 0.8568\n",
            "precision value is 0.872654370489174\n",
            "recall value is 0.8452695354979027\n",
            "f1 value is 0.8587436868686869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnV6FnuhY9vh",
        "outputId": "86b0404c-a219-4f26-ae81-0df53037459e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "exp = explainer.explain_instance(X_test.iloc[0], model.predict_proba, num_features=10)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lime/lime_text.py:114: FutureWarning: split() requires a non-empty pattern match.\n",
            "  self.as_list = [s for s in splitter.split(self.raw) if s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4AomVN2ZYL6",
        "outputId": "2692eb65-be1f-4d12-d0eb-a7beabc9d4ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "exp.as_list()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bad', -0.1601615589537048),\n",
              " ('garbage', -0.09699252638014245),\n",
              " ('love', 0.07413598207119855),\n",
              " ('don', -0.049779669011829085),\n",
              " ('life', 0.04437483913105965),\n",
              " ('canadian', 0.039792487093273474),\n",
              " ('acting', -0.03610956443061801),\n",
              " ('prepared', 0.03325497384887356),\n",
              " ('bean', 0.03184214977724494),\n",
              " ('seriously', -0.031702106078309096)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1ESkF3ybUDI"
      },
      "source": [
        "<h4>The non-normalized data gave a better result, it may be necessary to reconsider the construction of the model.</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGGShqdVbf-Z"
      },
      "source": [
        "<h4>What if we make tfidf with bigrams</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpUzwU8ubm5w"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[\"review\"], data[\"sentiment\"], random_state=7)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dFB7m5mbvLT"
      },
      "source": [
        "model = Pipeline([\n",
        "  (\"vec\", TfidfVectorizer(ngram_range=(1, 2))),\n",
        "  (\"classifier\", LogisticRegression()) \n",
        "])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMYDZypOdhcl",
        "outputId": "c76a045f-2282-4c36-8a2c-d7d7082f46f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data[\"sentiment\"]"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        positive\n",
              "1        positive\n",
              "2        positive\n",
              "3        negative\n",
              "4        positive\n",
              "           ...   \n",
              "49995    positive\n",
              "49996    negative\n",
              "49997    negative\n",
              "49998    negative\n",
              "49999    negative\n",
              "Name: sentiment, Length: 50000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5jnlrdIcVpV"
      },
      "source": [
        "y_train = y_train.map({\"positive\": 1, \"negative\": 0})\n",
        "y_test = y_test.map({\"positive\": 1, \"negative\": 0})"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5EwCs-ddTGv",
        "outputId": "d46b8a6f-9a36-4c6d-8708-9bc8b701b2ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17552    0\n",
              "20467    0\n",
              "49715    1\n",
              "31896    1\n",
              "11953    1\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y-XfCGqb2Au",
        "outputId": "6bfdf868-30e0-456d-c05e-e0cdccfb2949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vec',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMTmyiwRb5tU",
        "outputId": "d447a708-8ccf-43e0-c307-56e4f4db5c72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Model metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(model, X_test, y_test, metric)}\")"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model metrics\n",
            "accuracy value is 0.8948\n",
            "precision value is 0.9077786688051324\n",
            "recall value is 0.884375\n",
            "f1 value is 0.8959240205777602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Gag7PncL61",
        "outputId": "f2fa6d09-4129-4598-e12b-970eaa714b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "exp = explainer.explain_instance(X_test.iloc[0], model.predict_proba, num_features=10)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lime/lime_text.py:114: FutureWarning: split() requires a non-empty pattern match.\n",
            "  self.as_list = [s for s in splitter.split(self.raw) if s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0m_swbtfO5y",
        "outputId": "49c12d1d-93b5-42ae-cdb3-a2921b130ad3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "exp.as_list()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bad', -0.0683469707661816),\n",
              " ('Nothing', -0.03869948530360005),\n",
              " ('could', -0.03306958329835676),\n",
              " ('only', -0.03142686495621501),\n",
              " ('have', -0.029132448485572632),\n",
              " ('was', -0.0272307158833128),\n",
              " ('sit', -0.026830442888631956),\n",
              " ('Oh', -0.025459961344797048),\n",
              " ('love', 0.025213165598701157),\n",
              " ('so', -0.025015381921450672)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D33MoQmIft5L"
      },
      "source": [
        "<h4>Nothing has changed</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJdZxhVUfRHw"
      },
      "source": [
        "X_train = X_train.apply(spacy_text_normalizer)\n",
        "X_test = X_test.apply(spacy_text_normalizer)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiVSzb3Cf7Qn",
        "outputId": "86f4cd5f-42d7-40ed-be98-f23d98c88b46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vec',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3Ql50yOf-LM",
        "outputId": "dfeb47a3-ec38-47a9-be25-59c59a3b8d33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Model metrics\")\n",
        "for metric_name, metric in metrics.items():\n",
        "  print(f\"{metric_name} value is {get_metrics_values(model, X_test, y_test, metric)}\")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model metrics\n",
            "accuracy value is 0.85264\n",
            "precision value is 0.8800320769847634\n",
            "recall value is 0.8337638656739097\n",
            "f1 value is 0.8562734082397004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JFGTq_YgD40",
        "outputId": "082a76f7-1a87-47a2-9415-1b43a8a765ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "exp = explainer.explain_instance(X_test.iloc[0], model.predict_proba, num_features=10)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lime/lime_text.py:114: FutureWarning: split() requires a non-empty pattern match.\n",
            "  self.as_list = [s for s in splitter.split(self.raw) if s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqYc_zHhgFp9",
        "outputId": "137365af-8ba6-4c22-cac4-984c1e34dc13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "exp.as_list()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bad', -0.1645802619815616),\n",
              " ('love', 0.07631155208874402),\n",
              " ('garbage', -0.07149844312966842),\n",
              " ('don', -0.053789628647735135),\n",
              " ('life', 0.0432815885970151),\n",
              " ('acting', -0.03674254760344241),\n",
              " ('big', -0.03318199725161448),\n",
              " ('seriously', -0.023882311109545657),\n",
              " ('prepared', 0.020053678086675446),\n",
              " ('action', 0.01801978481976002)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9oMy3Sjgpy2"
      },
      "source": [
        "<h4>Although the accuracy of the model is lower, the results for what it is trained on look much more plausible. I think it is necessary to increase the dataset.</h4>"
      ]
    }
  ]
}