{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Expirements with some models for solving problem of binary classification of movies</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>First of all we need to import all modules</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The next step is to get data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_datasets_from_file(filename, label_column_name, test_size):\n",
    "    if not (0 <= test_size <= 1):\n",
    "        raise Exception(\"train_test_split must be from 0 to 1\")\n",
    "    data = pd.read_csv(filename)\n",
    "    if label_column_name not in data.columns:\n",
    "        raise Exception(f\"There is no column '{label_column_name}' in the data\")\n",
    "    X = data.drop([label_column_name], axis=1)\n",
    "    y = data[label_column_name]\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_datasets_from_file(\"IMDB_dataset.csv\", \"sentiment\", 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38094</th>\n",
       "      <td>As much as I love trains, I couldn't stomach t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40624</th>\n",
       "      <td>This was a very good PPV, but like Wrestlemani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49425</th>\n",
       "      <td>Not finding the right words is everybody's pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35734</th>\n",
       "      <td>I'm really suprised this movie didn't get a hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41708</th>\n",
       "      <td>I'll start by confessing that I tend to really...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "38094  As much as I love trains, I couldn't stomach t...\n",
       "40624  This was a very good PPV, but like Wrestlemani...\n",
       "49425  Not finding the right words is everybody's pro...\n",
       "35734  I'm really suprised this movie didn't get a hi...\n",
       "41708  I'll start by confessing that I tend to really..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38094    negative\n",
       "40624    positive\n",
       "49425    negative\n",
       "35734    positive\n",
       "41708    negative\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38094    0\n",
       "40624    1\n",
       "49425    0\n",
       "35734    1\n",
       "41708    0\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test = y_train.map({\"positive\": 1, \"negative\": 0}), y_test.map({\"positive\": 1, \"negative\": 0})\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Next, write functions for data processing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "stop_words = STOP_WORDS\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#function from EDA\n",
    "def spacy_text_normalizer(text):\n",
    "    tokens = re.sub(r\"<.*>\", \"\", text) #Remove all tags\n",
    "    tokens = parser(text) #Get doc from text\n",
    "    tokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens ] #Normalize words\n",
    "    tokens = [ word for word in tokens if word not in stop_words and word not in punctuations ] #Remove stop words and punctuation\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNormalizer(TransformerMixin):\n",
    "    def __init__(self, text_column_name):\n",
    "        self.text_column_name = text_column_name\n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        return [spacy_text_normalizer(text) for text in X[self.text_column_name]]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = TextNormalizer(\"review\")\n",
    "X_transformed_text = normalizer.fit_transform(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love trains stomach movie premise steal locomotive drive arkansas chicago hitting train way right impossible plot lines hit board imagine disgruntled nasa employees stealing crawler totes shuttles fro driving new york idea.<br /><br />having said nice try wilford brimely quaker oats best levon helm turns good performance dimwitted meaning sidekick bob balaban suitably wormy corporate guy little guy takes goliath story gets airing'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Now we are ready to make some experiments with our data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\"Random forest\": RandomForestClassifier(), \"Log reg\": LogisticRegression()}\n",
    "feature_extractors = {\"Count vectorizer\": CountVectorizer(), \"Tfidf vectorizer\": TfidfVectorizer()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    for feature_extractor_name, feature_extractor in feature_extractors.items():\n",
    "        pipeline = Pipeline([\n",
    "            (\"text_normalizer\", normalizer),\n",
    "            (feature_extractor_name, feature_extractor),\n",
    "            (classifier_name, classifier)\n",
    "        ])\n",
    "        pipelines.append(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\stani\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "for pipeline in pipelines:\n",
    "    pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics = {\n",
    "    \"accuracy\": metrics.accuracy_score,\n",
    "    \"precision\": metrics.precision_score,\n",
    "    \"recall\": metrics.recall_score,\n",
    "    \"f1\": metrics.f1_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vectorizer and Random forest\n",
      "Метрики\n",
      "accuracy value is 0.8149333333333333\n",
      "precision value is 0.843638440668285\n",
      "recall value is 0.7784951904071683\n",
      "f1 value is 0.8097587719298246\n",
      "\n",
      "\n",
      "Tfidf vectorizer and Random forest\n",
      "Метрики\n",
      "accuracy value is 0.8592\n",
      "precision value is 0.8664525625585441\n",
      "recall value is 0.8532085913822638\n",
      "f1 value is 0.8597795777453192\n",
      "\n",
      "\n",
      "Count vectorizer and Log reg\n",
      "Метрики\n",
      "accuracy value is 0.8756666666666667\n",
      "precision value is 0.861454912856782\n",
      "recall value is 0.898800896033733\n",
      "f1 value is 0.8797317340555878\n",
      "\n",
      "\n",
      "Tfidf vectorizer and Log reg\n",
      "Метрики\n",
      "accuracy value is 0.8956\n",
      "precision value is 0.8883301096067053\n",
      "recall value is 0.9077612333640795\n",
      "f1 value is 0.8979405630865486\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pipeline in pipelines:\n",
    "    print(list(pipeline.get_params().keys())[4] + \" and \" + list(pipeline.get_params().keys())[5])\n",
    "    print(\"Метрики\")\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    for metric_name, metric in metrics.items():\n",
    "        print(f\"{metric_name} value is {metric(y_test, y_pred)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The results are that logistic regression and tfidf are a first-to-go model. Then you need to try to adjust the hyperparameters of these models, which I will do in another notepad.</h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
